---
title: 2025年大模型技术综述：从发展历程、生命周期到多模态应用
date: 2025-10-28T05:54:14.065Z
tags: ["LLM", "综述"]
categories: ["LLM"]
description: 
---
# 文章引言
## 研究背景

大模型是指通过海量数据训练、参数规模达数十亿至万亿级别的深度学习模型，其核心特征包括庞大参数量、海量训练数据以及预训练与微调相结合的训练范式。从基于Transformer架构的NLP预训练模型起步，大模型已演进到能够协同处理文本、图像、音频等多模态信息的新阶段，正推动人工智能从专用工具向通用智能迈进，成为赋能各行业数字化转型的核心驱动力。

## 架构说明

本文围绕“发展历程—生命周期—模态划分—模型类型”四个核心维度系统梳理大模型技术：首先沿时间轴呈现从萌芽、范式开创、规模竞赛到智能时代的演进脉络；继而剖析数据准备、预训练、对齐安全至应用落地的完整生命周期；随后区分语言、视觉及多模态模型的技术特点；最后从基座模型与垂直行业应用双视角展开分析，最终总结现状并展望未来趋势。

# 发展历程

## 萌芽时期

- **2006年9月**：Geoffrey Hinton等人发表深度信念网络（DBN）论文，重启深度学习热潮，为后续大模型奠定理论基础。
- **2009年6月**：ImageNet数据集正式发布，提供百万级标注样本，催生“大数据+大算力”范式。
- **2012年10月**：AlexNet在ImageNet竞赛中夺冠，展示GPU训练大规模神经网络的潜力，开启“模型越大、性能越好”的认知。
- **2013年1月**：Google发布Word2Vec，首次将词向量扩展到300维，奠定大规模预训练范式雏形。
- **2014年1月**：Ian Goodfellow提出GAN，生成式模型迎来新路线，为后续AIGC埋伏笔。
- **2015年12月**：微软亚洲研究院发布152层ResNet，首次把深度卷积网络推进到百层以上，验证“深度+大数据”路径。
- **2016年11月**：Google Neural Machine Translation（GNMT）上线，首次用8层LSTM端到端训练10^8量级参数系统，为后续“大模型+大语料”提供工程模板。

## 架构奠基

- **2017年6月**：Google发布《Attention Is All You Need》，提出Transformer架构，完全抛弃循环/卷积，奠定现代大模型基础。
- **2017年12月**：Transformer官方代码开源，奠定后续Megatron、FairSeq、HuggingFace等生态底座。
- **2018年6月**：OpenAI发布GPT-1（1.17亿参数），首次证明“无监督预训练+有监督微调”在语言任务上的通用性。
- **2018年10月**：Google发布BERT（3.4亿参数），引入双向编码+掩码语言模型，刷新11项NLP基准，引爆预训练范式。
- **2018年11月**：Google发布T5（Text-to-Text Transfer Transformer），统一所有NLP任务为“text-to-text”格式，确立后续大模型任务接口标准。

## 规模竞赛

- **2019年2月**：OpenAI发布GPT-2（15亿参数），因“生成内容过于逼真”被暂缓开源，首次引发“大模型安全”讨论。
- **2019年7月**：英伟达发布Megatron-LM（83亿参数），首次用模型并行训练十亿级Transformer，验证“大算力+大模型”工程路径。
- **2020年1月**：Microsoft DeepSpeed开源，ZeRO优化器让千亿级模型训练内存降低一个数量级，奠定“大模型平民化”工程底座。
- **2020年5月**：OpenAI发布GPT-3（1750亿参数），在少样本/零样本场景展现涌现能力，开启“提示工程”时代。
- **2020年7月**：Google发布Switch Transformer（1.6万亿参数），首次将稀疏MoE（混合专家）架构推至万亿规模。
- **2021年1月**：OpenAI发布CLIP & DALL·E，首次打通文本-图像跨模态，大模型走出纯文本。
- **2021年5月**：华为发布盘古α（2000亿参数），国内首个千亿级中文预训练模型。
- **2021年7月**：北京智源研究院发布悟道2.0（1.75万亿参数），全球最大中文多模态大模型，首次把“国画、诗词、蛋白质”统一预训练。
- **2021年10月**：微软与英伟达联合推出Megatron-Turing NLG（5300亿参数），刷新语言模型参数纪录。
- **2022年4月**：Google发布PaLM（5400亿参数），在数百项任务上验证“规模-性能”对数线性关系。
- **2022年9月**：Meta发布Make-A-Video，实现文本到视频生成，大模型向多模态时空生成扩展。

## 智能时代

- **2022年11月**：OpenAI发布ChatGPT，5天用户破百万，开启“对话式AI”消费级爆发。
- **2023年1月**：ChatGPT月活破1亿，成为史上增长最快的消费级应用，引发“AI+搜索”全球竞赛。
- **2023年2月**：微软集成ChatGPT到Bing，首次让大模型重塑互联网搜索入口。
- **2023年3月**：OpenAI发布GPT-4（支持图文多模态），在律考、SAT等考试超越90%人类，大模型进入“通用智能”讨论。
- **2023年3月**：百度发布文心一言，国内首个对标ChatGPT的大模型产品。
- **2023年4月**：阿里发布通义千问，开启国内云端大模型API生态。
- **2023年5月**：Sam Altman在美国国会听证，提出“AI需要像核设施一样监管”，全球开启大模型合规立法潮。
- **2023年6月**：华为发布盘古3.0（1000亿参数行业大模型），聚焦B端制造、气象、药物等场景。
- **2023年7月**：Meta免费开源Llama 2（700亿参数），可商用许可证重塑开源大模型格局。
- **2023年8月**：中国《生成式AI服务管理暂行办法》正式施行，大模型进入“备案+安全评估”阶段。
- **2023年9月**：OpenAI发布DALL·E 3，原生集成至ChatGPT，实现“对话式高精度绘图”。
- **2023年10月**：Anthropic发布Claude 2（200K上下文），把安全对齐与长文本同时推进到商用级。
- **2023年11月**：OpenAI首届开发者大会发布GPT-4 Turbo与GPTs，开启“个人化、可商用Agent商店”。
- **2024年1月**：谷歌发布Gemini 1.0 Ultra，首次在MMLU基准上公开超越GPT-4，多模态原生支持音视频。
- **2024年2月**：OpenAI发布Sora，支持60秒1080p文本到视频生成，大模型进入“世界模拟器”阶段。
- **2024年3月**：月之暗面（Moonshot AI）发布Kimi Chat，支持200万字长上下文，刷新消费级长文本纪录。
- **2024年4月**：微软发布Phi-3-mini（3.8B参数），在iPhone端侧跑通，开启“小参数大能力”端化趋势。
- **2024年5月**：Google发布Gemini 1.5 Pro（100万token上下文），多模态长文档理解能力再突破。
- **2024年6月**：Meta发布Llama 3.1（4050亿参数），开源领域首个4000亿级稠密模型，性能对标GPT-4。
- **2024年7月**：上海AI Lab发布InternVL2-40B，开源最强多模态大模型，在OCR、视频、中文图表等任务霸榜。
- **2024年9月**：OpenAI发布o1系列，引入“思维链”强化学习推理范式，在数学、代码、科学问答上显著超越GPT-4。
- **2024年10月**：欧盟《AI Act》正式生效，全球首个具有法律约束力的通用AI监管法规落地。
- **2024年11月**：DeepSeek发布R1-Lite预览版，轻量推理模型首次公开体验。
- **2025年1月10日**：DeepSeek官方移动应用上线。
- **2025年1月20日**：DeepSeek开源DeepSeek-R1（671B MoE），以1/20成本实现对标OpenAI o1的推理能力，登顶中美App Store免费榜。
- **2025年1月29日**：阿里云通义千问发布Qwen2.5-Max，预训练数据超20万亿tokens，位列全球第七、非推理类中国模型第一。
- **2025年2月3日**：国家超算互联网平台上线DeepSeek-R1/V3，三大运营商同步接入，提供百万tokens仅6元的普惠API。
- **2025年3月15日**：百度文心4.5-Turbo发布，首次支持512 k上下文与多图一键PPT生成，主攻办公场景。
- **2025年3月22日**：腾讯混元3D世界模型1.0开源，业界首个可沉浸漫游、可交互、可仿真的3D世界生成基座模型。
- **2025年4月18日**：阶跃星辰开源Step-3（MoE-1.8T），国产芯片32 k推理速度达DeepSeek R1的300%，主打“轻量视觉路径”。
- **2025年5月1日**：华为盘古σ-Weather上线，率先在台风路径48 h预报中将误差缩小至35 km，中央气象局正式商用。
- **2025年5月20日**：荣耀开源MagicGUI-7B多模态感知模型，支撑手机端AI Agent自动执行，与高通8 Gen 4深度耦合。
- **2025年6月8日**：科大讯飞星火X1升级版上线，全国产算力训练，医疗诊断辅助准确率在三甲医院试点超95%。
- **2025年7月15日**：谷歌云Gemini 2.0 Turbo向企业开放微调接口，支持金融、法律专有数据集深度定制。
- **2025年7月25日**：市场消息：OpenAI计划8月初发布GPT-5（pro/mini/nano三版本），同时释出类似o3-mini的开放权重模型。
- **2025年8月1日**：OpenAI正式推出GPT-5系列，夺回LMSYS总榜第一；pro版整合o系列推理，mini/nano主攻端侧与API。
- **2025年8月21日**：DeepSeek发布V3.1，采用“混合推理架构”，支持国产昇腾/H100，推理成本再降30%，开启AI大模型“架构竞赛”。
- **2025年9月5日**：蚂蚁集团开源扩散语言模型推理框架dInfer，推理速度提升3×，助力国产芯片生态。
- **2025年9月12日**：Anthropic发布Claude Sonnet 4.5与Haiku 4.5，新增上下文编辑与内存工具，编码性能冲至SWE-bench 74.5%。
- **2025年9月20日**：上海AI Lab开源InternVL2-40B，OCR、视频、中文图表任务霸榜，成为最强开源多模态基座。
- **2025年10月12日**：字节跳动发布万亿参数多模态大模型“云雀-Ω”，支持视频-文本-3D实时生成，首批落地零售虚拟货架。
- **2025年10月13日**：阿里巴巴发布Qwen3-Max（万亿参数闭源）与Qwen3-Omni（开源实时交互），同步开放金融/教育/医疗行业方案。
- **2025年10月16日**：中国移动“九天医疗大模型2.0”发布，支持800+疾病辅助诊断，已在上海多家三甲医院试点。
- **2025年10月19日**：国内“模型峰会”——蚂蚁Ling-1T、讯飞星火4.0 Turbo、阿里Qwen3-VL-Flash、百度多语言OCR、字节视频生成同日亮相。
- **2025年10月25日**：远景科技发布全球首款“AI风储一体机”；首驱科技推出AI电动两轮车，无感解锁+开放API，AI深入能源与出行。

# 生命周期

## 数据准备
- **数据合成与增强**  
  - 前沿：基于LLM的“合成→验证→再训练”闭环（如Microsoft Copilot数据飞轮）  
  - 技术：Self-Instruct、Evol-Instruct、Backtranslation，支持多模态图文对自动生成  
- **数据治理与去毒**  
  - 前沿：D4Data框架——用Diffusion检测并擦除隐私/版权像素，NLP侧用RLHF过滤有毒文本  
  - 技术：Lineage追踪 + 差分隐私，满足GDPR/CCPA合规  
- **多模态统一表示**  
  - 前沿：LAION-5B→LAION-2B-en-mined，CLIP-Filter V3，实现图文对齐质量≥95 %  
  - 技术：Sentence-Transformers + Vision-Transformer 联合Embedding，支持128语言  

## 模型预训
- **MoE稀疏化**  
  - 前沿：Google PaLM 2-540B，Top-2 Routing + Expert Choice，激活参数量仅8 %  
  - 技术：ST-MoE、MegaBlocks（GPU kernel级优化），训练成本↓37 %  
- **Retrieval-Augmented Pre-training**  
  - 前沿：Retro++、RALLM，在预训练阶段即引入20 M外部知识切片  
  - 技术：KNN-Transformer + Continual-IndexRebuild，实现“事实可更新”  
- **序列长度外推**  
  - 前沿：LongNet-1B-token（Microsoft）， dilated attention，复杂度O(n·log n)  
  - 技术：FlashAttention-2 + ALiBi→xPos，单卡A100支持2 M token  

## 微调适配
- **参数高效微调（PEFT）**  
  - 前沿：QLoRA（4-bit量化+LoRA），65B模型在单卡48 GB完成微调；  
  - 技术：LoRA-GA（Gradient Approximation）初始化，下游任务平均↑1.8 %  
- **Instruction Tuning规模化**  
  - 前沿：TÜLU 3-1100任务混合，Llama-2-70B↑13 %优于GPT-3.5-turbo  
  - 技术：Chain-of-Thought + Flan-Muffin数据配比自动搜索  
- **多模态指令微调**  
  - 前沿：LLaVA-1.5-34B，图文交错指令120万，MMBench↑7 %  
  - 技术：Vision-Token Sampling + 位置插值，支持任意分辨率输入  

## 对齐安全
- **RLHF规模化**  
  - 前沿：Anthropic Constitutional AI-52B，自监督规则+AI反馈，人工标注↓90 %  
  - 技术：RRHF（Rank Response）、DPO（Direct Preference Optimization）  
- **红队对抗与防御**  
  - 前沿：HarmBench + DecodingTrust，自动化生成5 k+有害提示，覆盖Prompt-Injection、Jailbreak  
  - 技术：Self-Refine + Safety-Filter Router，拒绝率↑28 %  
- **可解释对齐**  
  - 前沿：OpenAI GPT-4-1106 system card，使用稀疏自编码器（SAE）定位“说谎”神经元  
  - 技术：Activation Patching + Causal Mediation，实现概念级干预  

## 压缩部署
- **量化**  
  - 前沿：SmoothQuant-α（W8A8）、KVQuant-4bit，LLaMA-70B精度损失&lt;0.3 %  
  - 技术：LLM.int8()混合精度、Zero-Quant-V2，首token延迟↓42 %  
- **剪枝+蒸馏**  
  - 前沿：SliceGPT-30B，结构化剪枝50 %，下游任务↑1.1 %；  
  - 技术：SparseGPT一次性剪枝，支持N:M 2:4稀疏  
- **边缘侧框架**  
  - 前沿：MLC-LLM、Llama.cpp，4-bit量化Llama-7B在iPhone 15 Pro跑通8 tok/s  
  - 技术：ARM NEON + Metal kernel融合，内存占用&lt;4 GB  

## 推理优化
- **分布式推理**  
  - 前沿：NVIDIA TensorRT-LLM + FP8，GPT-175B单DGX-H100节点吞吐↑5×  
  - 技术：Continuous Batching + PagedAttention，最大并发↑20×  
- **投机解码**  
  - 前沿：Google Medusa、Meta SpecInfer，2-3倍加速；  
  - 技术：Draft-Model为原模型1/10，基于RNN-LM的Tree-Attention验证  
- **边缘-云协同**  
  - 前沿：Split-LLM，将Attention层卸载至云端，FFN层留在边缘，带宽↓70 %  
  - 技术：Sliding-Window + KV-Cache增量同步，端到端延迟&lt;300 ms  

## 应用落地
- **AI Agent生态**  
  - 前沿：AutoGPT-4 + LangChain-0.1，多工具调用（浏览器、Python、API）  
  - 技术：ReAct + Self-Reflection，任务完成率↑至68 %  
- **垂直行业大模型**  
  - 医疗：Med-PaLM 2，美国USMLE≥86 %及格线；  
  - 法律：Harvey-Llama-65B，合同审查准确率92 %；  
  - 制造：Bosch Industrial-LLM，设备故障预测F1↑11 %  
- **多模态创作**  
  - 前沿：Stable Diffusion XL + LLM Storyboard，一键生成15 s短视频；  
  - 技术：LLM-driven Prompt Refiner + Style-Lora，支持4 K@60 fps  

## 评测监控
- **通用基准**  
  - MMLU-Pro、CMMLU、TruthfulQA v2，覆盖STEM/人文/安全  
- **能力细粒度**  
  - HELM-2：114场景、6大指标（准确性、鲁棒性、公平性、效率、毒性、不确定性）  
- **动态红队监控**  
  - 前沿：Constitutional-Loop，每日自动更新1 k+新攻击模板  
  - 技术：LLM-as-a-Judge + Elo-MMR，实现24×7在线安全仪表盘  
- **生产级可观测**  
  - 前沿：OpenLLMetry，Prometheus + Grafana，Token级P99延迟、成本、碳排  
  - 技术：Span-Level Tracing，支持LangChain/LlamaIndex零代码接入  

# 大模型不同模态技术路线与研究现状

## 模态划分

### 语言模型
- **技术路线**  
  - **GPT 模式**：自回归生成，Decoder-Only，以“Next-Token Prediction”为核心，适合开放端生成、少样本/零样本场景。  
  - **BERT 模式**：双向编码，Encoder-Only，以 MLM（掩码语言模型）为目标，擅长理解类、分类与抽取任务。  
  - **T5/Encoder-Decoder 模式**：统一“Text-to-Text”框架，兼顾理解与生成，中等规模下在垂直领域微调效果稳定。  

- **研究现状**  
  - 百亿级以上参数几乎全部采用 GPT 路线，强调规模化、无监督预训练 + 人类反馈强化学习（RLHF）。  
  - 2023-2025 年焦点：  
    1) 超长上下文（&gt;2M tokens）  
    2) 工具调用/插件闭环  
    3) 低能耗推理（量化、MoE、投机解码）  
    4) 领域适配（继续预训练 + 指令微调）。  

- **顶级模型**  
  - **闭源**：OpenAI GPT-4o、Google Gemini-1.5-Pro、Anthropic Claude-3.5-Sonnet、Microsoft Copilot-GPT。  
  - **开源**：Meta Llama-3.1-405B、Mistral-8×22B、Qwen2.5-72B、DeepSeek-67B-MoE。  

### 视觉模型
- **技术路线**  
  - **CNN → Transformer**：ViT 将图像切块做纯 Transformer 建模，后续 Swin、ConvNeXt 引入局部归纳偏置。  
  - **自监督预训练**：MAE、BEiT、iBOT 通过掩码重建学习通用表征；DINOv2 无需标签即可提取稠密特征。  
  - **扩散/生成模型**：LDM/Stable Diffusion 系列把生成任务映射到隐空间，实现高分辨率文生图、图生图。  

- **研究现状**  
  - 2024-2025 年重点：  
    1) 统一视觉任务（分割、检测、深度、姿态）的“Vision-Language” backbone  
    2) 任意分辨率/长边输入  
    3) 视频时空建模（ViViT、InternVideo、Sora-like DiT）  
    4) 3D 生成（3D-VAE、Gaussian Splatting）。  

- **顶级模型**  
  - **通用视觉**：ViT-G/22B、Swin-v2-G、InternImage-H  
  - **自监督**：DINOv2-giant、MAE-H  
  - **生成**：Stable Diffusion XL、SD3-Ultra、Google Imagen-2、OpenAI DALL·E-3、Sora（视频）  

### 多模态模型
- **技术路线**  
  1. **LLM+VFM 拼接**：语言模型负责推理，视觉基础模型输出特征或掩码，模块化易落地但存在跨模态断层。  
  2. **VLM 对齐融合**：图文双塔 → 对比学习 → 联合 Transformer，实现图文互检、视觉问答。  
  3. **VLA 端到端**：在 VLM 基础上新增动作 token，直接输出机器人/车辆控制，形成“感知-推理-行为”闭环。  
  4. **全模态大模型**：视觉-语言-语音-触觉-3D 统一表征，以任意模态为输入/输出，迈向“通用世界模型”。  

- **研究现状**  
  - 2023-2025 关键突破：  
    - 视觉指令微调（LLaVA、MiniGPT-4）  
    - 任意分辨率动态切图（InternLM-XComposer-2.5、Qwen-VL-Chat）  
    - 视频对话与长时序记忆（Video-ChatGPT、LongVA）  
    - 具身智能 VLA 零样本泛化（RT-2、RT-H、GR00T N1、Gemini Robotics）  
    - 多模态 MoE、LoRA/QLoRA 低成本微调。  

- **顶级模型**  
  - **通用多模态**：GPT-4V/GPT-4o、Gemini-1.5-Pro、Claude-3-Opus、Qwen2.5-VL-72B、InternVL2-108B  
  - **开源 VLM**：LLaVA-1.6-34B、MiniCPM-V-2.6、BakLLaVA-1.5、CogVLM-17B  
  - **VLA/具身**：Google RT-2-H、PaLM-E-562B、NVIDIA GR00T N1、Octo、Gemini Robotics  
  - **全模态探索**：MIT/IBM MultiPLY、Meta ImageBind、Microsoft i-Code V3  

# 模型类型
## 基座模型
（以公司分类，介绍国内和国外的基座大模型）
### 国内模型
### 国外模型
## 垂直模型
（以领域分类，介绍垂直行业的大模型）

# 总结展望
## 技术总结
（总结文章内容）
## 未来展望
（展望未来大模型技术发展）
